{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## <center>CSE 546: Reinforcement Learning</center>\n",
    "### <center>Prof. Alina Vereshchaka</center>\n",
    "#### <center>Spring 2025</center>\n",
    "\n",
    "Welcome to the Assignment 3, Part 1: Introduction to Actor-Critic Methods! It includes the implementation of simple actor and critic networks and best practices used in modern Actor-Critic algorithms."
   ],
   "id": "cf4d8c9b006ada45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0: Setup and Imports",
   "id": "9d7a6d891e2fb312"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ],
   "id": "53473293aa9daf8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Section 1: Actor-Critic Network Architectures and Loss Computation\n",
    "\n",
    "In this section, you will explore two common architectural designs for Actor-Critic methods and implement their corresponding loss functions using dummy tensors. These architectures are:\n",
    "- A. Completely separate actor and critic networks\n",
    "- B. A shared network with two output heads\n",
    "\n",
    "Both designs are widely used in practice. Shared networks are often more efficient and generalize better, while separate networks offer more control and flexibility.\n",
    "\n",
    "---\n"
   ],
   "id": "2a3d9c34ff222994"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 1a â€“ Separate Actor and Critic Networks with Loss Function\n",
    "\n",
    "Define a class `SeparateActorCritic`. Your goal is to:\n",
    "- Create two completely independent neural networks: one for the actor and one for the critic.\n",
    "- The actor should output a probability distribution over discrete actions (use `nn.Softmax`).\n",
    "- The critic should output a single scalar value.\n",
    "\n",
    " Use `nn.ReLU()` as your activation function. Include at least one hidden layer of reasonable width (e.g. 64 or 128 units).\n",
    "\n",
    "```python\n",
    "# TODO: Define SeparateActorCritic class\n",
    "```\n",
    "\n",
    " Next, simulate training using dummy tensors:\n",
    "1. Generate dummy tensors for log-probabilities, returns, estimated values, and entropies.\n",
    "2. Compute the actor loss using the advantage (return - value).\n",
    "3. Compute the critic loss as mean squared error between values and returns.\n",
    "4. Use a single optimizer for both the Actor and the Critic. In this case, combine the actor and critic losses into a total loss and perform backpropagation.\n",
    "5. Use a separate optimizers for both the Actor and the Critic. In this case, keep the actor and critic losses separate and perform backpropagation.\n",
    "\n",
    "```python\n",
    "# TODO: Simulate loss computation and backpropagation\n",
    "```\n",
    "\n",
    "ðŸ”— Helpful references:\n",
    "- PyTorch Softmax: https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
    "- PyTorch MSE Loss: https://pytorch.org/docs/stable/generated/torch.nn.functional.mse_loss.html\n",
    "\n",
    "---"
   ],
   "id": "971fa7887dd4f858"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Define a class SeparateActorCritic with separate networks for actor and critic\n",
    "\n",
    "# BEGIN_YOUR_CODE\n",
    "\n",
    "\n",
    "# END_YOUR_CODE"
   ],
   "id": "dd6b81ed1791e4e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
    "\n",
    "YOUR ANSWER:"
   ],
   "id": "eb8e90c88108cd2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "98ea382314354335",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 1b â€“ Shared Network with Actor and Critic Heads + Loss Function\n",
    "\n",
    "Now define a class `SharedActorCritic`:\n",
    "- Build a shared base network (e.g., linear layer + ReLU)\n",
    "- Create two heads: one for actor (output action probabilities) and one for critic (output state value)\n",
    "\n",
    "```python\n",
    "# TODO: Define SharedActorCritic class\n",
    "```\n",
    "\n",
    "Then:\n",
    "1. Pass a dummy input tensor through the model to obtain action probabilities and value.\n",
    "2. Simulate dummy rewards and compute advantage.\n",
    "3. Compute the actor and critic losses, combine them, and backpropagate.\n",
    "\n",
    "```python\n",
    "# TODO: Simulate shared network loss computation and backpropagation\n",
    "```\n",
    "\n",
    " Use `nn.Softmax` for actor output and `nn.Linear` for scalar critic output.\n",
    "\n",
    "ðŸ”— More reading:\n",
    "- Policy Gradient Methods: https://spinningup.openai.com/en/latest/algorithms/vpg.html\n",
    "- Actor-Critic Overview: https://www.tensorflow.org/agents/tutorials/6_reinforce_tutorial\n",
    "- PyTorch Categorical Distribution: https://pytorch.org/docs/stable/distributions.html#categorical\n",
    "\n",
    "---"
   ],
   "id": "64081a606b93029d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# BEGIN_YOUR_CODE\n",
    "\n",
    "\n",
    "# END_YOUR_CODE"
   ],
   "id": "a48f882fff11aecc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
    "\n",
    "YOUR ANSWER:"
   ],
   "id": "a974e302d1fdb028"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8fad5ea9406f8b4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Section 2: Auto-Adaptive Network Setup for Environments\n",
    "\n",
    "You will now create a function that builds a shared actor-critic network that adapts to any Gymnasium environment. This function should inspect the environment and build input/output layers accordingly."
   ],
   "id": "eb645eb009b85b1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2: Auto-generate Input and Output Layers\n",
    "Write a function `create_shared_network(env)` that constructs a neural network using the following rules:\n",
    "- The input layer should match the environment's observation space.\n",
    "- The output layer for the **actor** should depend on the action space:\n",
    "  - For discrete actions: output probabilities using `nn.Softmax`.\n",
    "  - For continuous actions: output mean and log std for a Gaussian distribution.\n",
    "- The **critic** always outputs a single scalar value.\n",
    "\n",
    "```python\n",
    "# TODO: Define function `create_shared_network(env)`\n",
    "```\n",
    "\n",
    "#### Environments to Support:\n",
    "Test your function with the following environments:\n",
    "1. `CliffWalking-v0` (Use one-hot encoding for discrete integer observations.)\n",
    "2. `LunarLander-v3` (Standard Box space for observations and discrete actions.)\n",
    "3. `PongNoFrameskip-v4` (Use gym wrappers for Atari image preprocessing.)\n",
    "4. `HalfCheetah-v5` (Continuous observation and continuous action.)\n",
    "\n",
    "```python\n",
    "# TODO: Loop through environments and test `create_shared_network`\n",
    "```\n",
    "\n",
    "Hint: Use `gym.spaces` utilities to determine observation/action types dynamically.\n",
    "\n",
    "ðŸ”— Observation/Action Space Docs:\n",
    "- https://gymnasium.farama.org/api/spaces/\n",
    "\n",
    "---"
   ],
   "id": "4223b6ddf43abee5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# BEGIN_YOUR_CODE\n",
    "\n",
    "\n",
    "# END_YOUR_CODE"
   ],
   "id": "d6d249ff9277403a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
    "\n",
    "YOUR ANSWER:"
   ],
   "id": "4ccd13f0b62b30ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ee2dd81024ce246a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 3: Write Observation Normalization Function\n",
    "Create a function `normalize_observation(obs, env)` that:\n",
    "- Checks if the observation space is `Box` and has `low` and `high` attributes.\n",
    "- If so, normalize the input observation.\n",
    "- Otherwise, return the observation unchanged.\n",
    "\n",
    "```python\n",
    "# TODO: Define `normalize_observation(obs, env)`\n",
    "```\n",
    "\n",
    "Test this function with observations from:\n",
    "- `LunarLander-v3`\n",
    "- `PongNoFrameskip-v4`\n",
    "\n",
    "Note: Atari observations are image arrays. Normalize pixel values to [0, 1]. For LunarLander-v3, the different elements in the observation vector have different ranges. Normalize them to [0, 1] using the `low` and `high` attributes of the observation space.\n",
    "\n",
    "\n",
    "---"
   ],
   "id": "b39c886fa536a639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# BEGIN_YOUR_CODE\n",
    "\n",
    "\n",
    "# END_YOUR_CODE"
   ],
   "id": "fc7ee06112cf7d29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
    "\n",
    "YOUR ANSWER:"
   ],
   "id": "501ed2a6e7ca7a7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "78211b617a843f62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Section 4: Gradient Clipping\n",
    "\n",
    "To prevent exploding gradients, it's common practice to clip gradients before optimizer updates.\n",
    "\n",
    "### Task 4: Clip Gradients for Actor-Critic Networks\n",
    "Use dummy tensors and apply gradient clipping with the following PyTorch method:\n",
    "```python\n",
    "# During training, after loss.backward():\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "```\n",
    "\n",
    "Reuse the loss computation from Task 1a or 1b. After computing the gradients, apply gradient clipping.\n",
    "Print the gradient norm before and after clipping to verify itâ€™s applied.\n",
    "\n",
    "ðŸ”— PyTorch Docs: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html\n",
    "\n",
    "\n",
    "---"
   ],
   "id": "6b5fb5353307f514"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# BEGIN_YOUR_CODE\n",
    "\n",
    "\n",
    "# END_YOUR_CODE"
   ],
   "id": "7327507fb6e803ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
    "\n",
    "YOUR ANSWER:"
   ],
   "id": "9952750fa74cd487"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "557a9303f5a1c863",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you are working in a team, provide a contribution summary.\n",
    "| Team Member | Step# | Contribution (%) |\n",
    "|---|---|---|\n",
    "|   | Task 1 |   |\n",
    "|   | Task 2 |   |\n",
    "|   | Task 3 |   |\n",
    "|   | Task 4 |   |\n",
    "|   | **Total** |   |\n"
   ],
   "id": "f4cff31e6c6e7e4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4be0a6e29f281e23",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
